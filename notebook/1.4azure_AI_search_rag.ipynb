{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "        api_key=os.getenv(\"aozai_api_key\"),  \n",
    "        api_version=os.getenv(\"aoai_llm_api_version\"),\n",
    "        azure_endpoint=os.getenv(\"aoai_resource_uri\")\n",
    "    )\n",
    "\n",
    "def get_embedding(text):\n",
    "    get_embeddings_response = openai_client.embeddings.create(model=os.getenv(\"aoai_embedding_model_name\"), input=text)\n",
    "    return get_embeddings_response.data[0].embedding\n",
    "\n",
    "# Initialize Azure search client\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_creds = AzureKeyCredential(os.getenv(\"AZURE_SEARCH_API_KEY\"))\n",
    "\n",
    "AZURE_SEARCH_FULL_INDEX = \"envision-qa-index\"\n",
    "search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_FULL_INDEX, credential=search_creds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare user question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"咨询电脑下载腾讯会议软件问题\"\n",
    "user_question_vector = get_embedding(user_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve matching documents\n",
    "\n",
    "The search call below does a **hybrid search**, performing both a full-text search and a vector search in parallel.\n",
    "It merges those results using Reciprocal Rank Fusion (RRF). \n",
    "Finally, it re-ranks the merged results using the AI Search semantic ranker, a re-ranking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[电脑上能下载腾讯会议嘛？]: 告知腾讯会议软件不在IT标准软件列表中，如因工作需要安装，需向本体系信息安全专员咨询，并且注意该软件License相关规则。\n",
      "如何确认信息安全员：\n",
      "企业微信 - 工作台 - 信息安全委员会 - More -专员 中查看\n",
      "\n",
      "\n",
      "[咨询电脑下载腾讯会议软件问题]: 腾讯会议软件不在IT标准软件列表中，如因工作需要安装，需向本体系信息安全专员咨询，并且注意该软件License相关规则。\n",
      "如何确认信息安全员：\n",
      "企业微信 - 工作台 - 公司信息安全委员会-More-安全专员/信管办主任\n",
      "如查询不到负责的安全员可联系信管办主任\n",
      "\n",
      "\n",
      "[公司电脑上可以下载腾讯会议及腾讯文档软件吗？]: 该软件不在IT标准软件列表中，如因工作需要安装，需向本体系信息安全专员咨询，并且注意该软件License相关规则。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = search_client.search(\n",
    "        user_question,\n",
    "        top=3, \n",
    "        vector_queries=[\n",
    "                VectorizedQuery(vector=user_question_vector, k_nearest_neighbors=50, fields=\"question_embedding,answer_embedding\")],\n",
    "        query_type=\"semantic\",\n",
    "        semantic_configuration_name=\"default\")\n",
    "\n",
    "sources = \"\\n\\n\".join([f\"[{doc['question']}]: {doc['answer']}\\n\" for doc in r])\n",
    "\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send question and documents to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "腾讯会议软件不在公司IT标准软件列表中，如因工作需要安装，需向本体系信息安全专员咨询，并注意该软件的License相关规则。您可以通过以下方式确认信息安全专员：企业微信 - 工作台 - 信息安全委员会 - More - 安全专员/信管办主任。如果查询不到负责的安全员，可联系信管办主任。[电脑上能下载腾讯会议嘛？][咨询电脑下载腾讯会议软件问题][公司电脑上可以下载腾讯会议及腾讯文档软件吗？]\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"\n",
    "Assistant helps company employees questions about the employee handbook. Be brief in your answers.\n",
    "Answer ONLY with the facts listed in the list of sources below.\n",
    "If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below.\n",
    "Each source has a name followed by colon and the actual information, include the source name for each fact you use.\n",
    "Use square brackets to reference the source, for example [info1.txt].\n",
    "\"\"\"\n",
    "USER_MESSAGE = user_question + \"\\nSources: \" + sources\n",
    "\n",
    "# Now we can use the matches to generate a response\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
